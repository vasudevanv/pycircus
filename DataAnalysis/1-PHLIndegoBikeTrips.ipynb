{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis of Indego City Bike trip data\n",
    "\n",
    "This notebook contains some examples of data analysis using python. We use the trip data from Philadelphia's Indego City Bike program. The data is released on a quartely basis by the City of Philadelphia and is available freely as CSV files through the city's portal for the bike share program. We have collected data into the `Indego-trip-data` folder. The folder has been zipped to keep the size small. We read the file directly from the zip below. The files are organized as\n",
    "\n",
    "1. `indego-stations.csv` - Station names and IDs\n",
    "2. `indego-trips-{yyyy}-q{n}.csv` - Trip data for year `{yyyy}` and quarter `{n}` which is between 1 and 4. We have data from the 2nd quarter of 2015 till the 4th quarter of 2019.\n",
    "\n",
    "We start by reading and analyzing data from the first file `indego-trips-2015-q2.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data into a pandas Dataframe\n",
    "\n",
    "Pandas (https://pandas.pydata.org/) is a extremely popular data analysis library. We will be using it extensively for analyzing this data set. There are also other approaches to analyze data of this type. We will note these methods in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import zipfile\n",
    "import pandas\n",
    "\n",
    "# Setup the file path for zip file\n",
    "data_folder = os.path.abspath('./data/')\n",
    "    \n",
    "# Read file from zip file\n",
    "zip_file = os.path.join(data_folder, 'Indego-trip-data.zip')\n",
    "\n",
    "def read_csv_from_zip(zf, fn):\n",
    "    \"\"\"Read a CSV file from a zip archive\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    zf : zipfile.ZipFile instance\n",
    "        ZipFile instance\n",
    "        \n",
    "    fn : str\n",
    "        String name for data file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Contents of CSV read into a DataFrame\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zf) as z:\n",
    "        matching = [s for s in z.namelist() if fn in s]\n",
    "        if not matching:\n",
    "            raise FileNotFoundError('File {} not in zip archive'.format(fn))\n",
    "        else:\n",
    "            zipped_data_file = matching[0]\n",
    "            # Read data from CSV file and confirm type of data\n",
    "            return pandas.read_csv(z.open(zipped_data_file))\n",
    "\n",
    "print(data_folder)\n",
    "print(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the file for analysis\n",
    "data_file = 'indego-trips-2015-q2.csv'\n",
    "data_2015_q2 = read_csv_from_zip(zip_file, data_file)\n",
    "type(data_2015_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First five entries in dataframe\n",
    "data_2015_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last five entries in dataframe\n",
    "data_2015_q2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trips = len(data_2015_q2)\n",
    "print(total_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe column headers\n",
    "\n",
    "The pandas.DataFrame is a custom data structure. The DataFrame object comes with \n",
    "\n",
    "* member variable/attribute/member - Values associated with the object\n",
    "* member functions - Functions that act on the data in the DataFrame\n",
    "\n",
    "Member variables are referred to by `<object_name>.<member variable>` and functions are referred to by `<object_name>.<member function name>()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_2015_q2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics of numerical columns\n",
    "\n",
    "DataFrame.describe() gets the summary statistics of only the columns that have numerical data. \n",
    "All other columns are ignored, unless you use the argument include='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015_q2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "\n",
    "Extracting a subset of data from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to a single data point using position\n",
    "print(data_2015_q2.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to a single data point using the index and column name\n",
    "print(data_2015_q2.loc[119555, \"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to a row of data\n",
    "print(data_2015_q2.loc[119555, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to a single column\n",
    "print(data_2015_q2.loc[:, \"trip_id\"])\n",
    "print(data_2015_q2[\"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a slice of data with some rows and columns\n",
    "print(data_2015_q2.loc[119550:119555, \"trip_id\":\"start_station_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 10 rows of data\n",
    "data_2015_q2.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a column from a DataFrame creates a pandas.Series\n",
    "start_times = data_2015_q2['start_time']\n",
    "type(start_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling time entries - datetime library\n",
    "\n",
    "Pandas contains extensive capabilities and features for working with time series data for all domains. It builds on the python's datetime library and NumPy's datetime64 and timedelta64. In our data set we have the starting time and ending tume for each trip that are part of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default the time data is read in as a string\n",
    "# This is not terribly useful format for dates and \n",
    "# times as we cannot do time operations on the data\n",
    "type(data_2015_q2.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to datetime\n",
    "# The following command replaces the values in-place. If you do not want this\n",
    "# you will need to create a copy of a DataFrame\n",
    "\n",
    "data_2015_q2['start_time'] = pandas.to_datetime(data_2015_q2['start_time']) \n",
    "data_2015_q2['end_time'] = pandas.to_datetime(data_2015_q2['end_time']) \n",
    "type(data_2015_q2.iloc[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using datetime - Number of trips in June\n",
    "\n",
    "We now want to extract a subset of the data using the start_time column as a reference and calculate the number of trips in June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime example\n",
    "# Datetime library allows us to create standardized date and \n",
    "# time formats and perform arithmetic and logical operations\n",
    "\n",
    "import datetime\n",
    "\n",
    "t1 = datetime.datetime(2019, 12, 31, 10, 0, 0)\n",
    "t2 = datetime.datetime(2020, 1, 1, 10, 0, 0)\n",
    "\n",
    "print(t2 - t1)\n",
    "print(t2 != t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime(year, month, day, hour, minute, second, microsecond)\n",
    "june_1 = datetime.datetime(2015,6,1,0,0,1)\n",
    "june_30 = datetime.datetime(2015,6,30,23,59,59)\n",
    "\n",
    "# .loc functionality allows for logical expressions for indexing\n",
    "# Here we use the & operator to filter all start_times between\n",
    "# June 1 and June 30\n",
    "\n",
    "data_2015_june = data_2015_q2.loc[(data_2015_q2['start_time'] > june_1) & (data_2015_q2['start_time'] < june_30)]\n",
    "len(data_2015_june)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average number of trips in each month of the quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the shortest, longest, and average trip lengths?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of trips from a given station\n",
    "\n",
    "pandas.Series has a member function `value_counts()` that counts the number of unique entries in the series. It returns a Series object indexed by the values being counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the starting station\n",
    "start_station_ids = data_2015_q2.loc[:,\"start_station_id\"]\n",
    "\n",
    "# Return a Series containing counts of unique values.\n",
    "start_station_tripcount = start_station_ids.value_counts()\n",
    "print(start_station_tripcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the index of value_counts() to look at number of trips from a given station\n",
    "start_station_tripcount.loc[3065]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing function to get the number of trips from a given station\n",
    "def n_trips_from(df, station_id):\n",
    "    \"\"\"Calculate the number of trips from a station\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Pandas dataframe containing trip data\n",
    "        \n",
    "    station_id: int\n",
    "        ID of the starting station\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    n_trips: int\n",
    "        Number of trips starting at station_id\n",
    "    \"\"\"\n",
    "    return df[\"start_station_id\"].value_counts().loc[station_id]\n",
    "\n",
    "n_trips_from(data_2015_q2, 3004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding station names based on station IDs\n",
    "\n",
    "The dataframe currently stores only the station IDs. There is a separate CSV file that contains the mapping between the station ID and station name. After reading the data we can use the `map` member function of a pandas.Series to create a new column where the value of the column is read from the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_names = read_csv_from_zip(zip_file, 'indego-stations.csv')\n",
    "station_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to have the station_names dataframe indexed by the station_id for the map to work\n",
    "station_names = station_names.set_index(station_names['station_id'])\n",
    "station_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the map function\n",
    "data_2015_q2['start_station_name'] = data_2015_q2['start_station_id'].map(station_names['station_name'])\n",
    "data_2015_q2[['start_station_id','start_station_name']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When are people riding?\n",
    "\n",
    "What hour of the day are most rides starting? To answer this question we need to create a histogram of the start_time data. Note that we have already converted this to datetime format, so we can easily extract the hour from datetime entry and build the histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure pandas approach\n",
    "# This indirectly calls matplotlib in the background\n",
    "%matplotlib inline\n",
    "\n",
    "data_2015_q2['start_time'].apply(lambda x: x.hour).hist(bins=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data using numpy and then plotting\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Empty list to hold hour data\n",
    "data_2015_q2_hr = []\n",
    "\n",
    "# Loop to extract hour from data frame\n",
    "for i, (xs, xe) in enumerate(zip(data_2015_q2['start_time'],data_2015_q2['end_time'])):\n",
    "    data_2015_q2_hr.append(xs.hour)\n",
    "    \n",
    "# Converting list to numpy    \n",
    "data_2015_q2_hr = numpy.array(data_2015_q2_hr)\n",
    "\n",
    "# Computing the histogram using numpy\n",
    "histogram, bin_edges = numpy.histogram(data_2015_q2_hr,bins=numpy.linspace(-0.50, 23.50, 25))\n",
    "print(histogram, bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matplotlib to create a figure and plot the histogram\n",
    "\n",
    "# Generate figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Generate a grid object\n",
    "gs = gridspec.GridSpec(1,1)\n",
    "\n",
    "# Add a axes to the grid\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "\n",
    "# Plot the histogram\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "ax.bar(bin_centers, histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also compute and plot the histogram in one matplotlib command\n",
    "# Notice the difference\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = gridspec.GridSpec(1,1)\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "histogram, bin_edges, patches = ax.hist(data_2015_q2_hr,bins=numpy.linspace(-0.50, 23.50, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can also use the pandas .dt.hour.value_counts() method to get the counts for each hour\n",
    "print(data_2015_q2['start_time'].dt.hour.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing several files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_file(year, quarter):\n",
    "    return 'indego-trips-{:d}-q{:d}.csv'.format(year, quarter)\n",
    "\n",
    "data = read_csv_from_zip(zip_file, data_file(2015,2))\n",
    "nrows = data.shape[0]\n",
    "\n",
    "for y in [2015, 2016, 2017, 2018, 2019]:\n",
    "    for q in [1,2,3,4]:\n",
    "        if y == 2015 and q < 2:\n",
    "            continue\n",
    "        else:\n",
    "            df = read_csv_from_zip(zip_file,data_file(y,q))\n",
    "            nrows += df.shape[0]\n",
    "            data = data.append(df)\n",
    "            print(data.shape[0])\n",
    "\n",
    "print(data.shape)\n",
    "print(nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [ [data_file(y,q) for q in [1,2,3,4] if not (y==2015 and q == 1)] \n",
    "          for y in [2015,2016,2017,2018,2019] ]\n",
    "files_flattened = [item for sublist in files for item in sublist]\n",
    "# print(files_flattened)\n",
    "\n",
    "files = [ data_file(y,q) for q in [1,2,3,4]  \n",
    "          for y in [2015,2016,2017,2018,2019]\n",
    "          if not (y==2015 and q == 1) ]\n",
    "\n",
    "dataframes = [read_csv_from_zip(zip_file,f) for f in files]\n",
    "data = pandas.concat(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data_2015_q2.groupby(['start_station_id','start_station_name']).size()\n",
    "counts.sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_start_stations(df, key='start_station_id'):\n",
    "    counts = df.groupby([key,'start_station_name']).size()\n",
    "    return counts.sort_values(ascending=False)[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
